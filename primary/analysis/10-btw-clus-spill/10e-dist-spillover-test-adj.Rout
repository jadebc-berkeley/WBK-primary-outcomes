
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> #####################################################
> # WASH Benefits Kenya
> # Primary analysis
> 
> # between-cluster spillovers
> 
> # Adjusted permutation test - primary outcomes
> # HAZ: endline data
> # diarrhea: midline and endline data
> 
> # by Jade (jadebc@berkeley.edu)
> #####################################################
> library(SuperLearner)
Loading required package: nnls
Super Learner
Version: 2.0-21
Package created on 2016-11-11

Warning message:
package ‘SuperLearner’ was built under R version 3.2.5 
> 
> rm(list=ls())
> 
> source("~/Documents/CRG/wash-benefits/kenya/src/primary/analysis/10-btw-clus-spill/10a-distance-functions.R")
> source("~/documents/crg/wash-benefits/kenya/src/primary/analysis/0-base-programs.R")
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

> 
> 
> #----------------------------------------------------
> # Read in distance matrices
> #----------------------------------------------------
> load("~/Dropbox/WBK-primary-analysis/Results/Jade/washb-dist-sub.RData")
> 
> #----------------------------------------------------
> # Read in outcome data - HAZ
> #----------------------------------------------------
> # load child length endline dataset
> e=read.csv("~/Dropbox/WASHB-Kenya-Data/1-primary-outcome-datasets/endline-anthro.csv",stringsAsFactors=TRUE)
> e=preprocess.anthro(e, "haz")
> e=preprocess.adj(e, "haz")
> 
> # subset to control compounds only
> e = subset(e,e$tr=="Control")
> 
> #----------------------------------------------------
> # Read in outcome data - diarrhea
> #----------------------------------------------------
> # load child length endline dataset
> data=read.csv("~/Dropbox/WASHB-Kenya-Data/1-primary-outcome-datasets/diarrhea.csv")
> d=preprocess.diarr(data)
> d=preprocess.adj(d, "diarr7")
> 
> # subset to control compounds only
> d = subset(d,d$tr=="Control")
> 
> # --------------------------------------
> # select covariates that are associated with the 
> # outcome
> # --------------------------------------
> # HAZ
> Wcols.haz=colnames(e)[-which(colnames(e)%in%c("block","hhid","childid","clusterid","tr","haz"))]
> Ws.haz=Wprescreen(Y=e$haz, Ws=e[,Wcols.haz],family="gaussian")

Likelihood Ratio Test P-values:
      [,1]          [,2]       
 [1,] "staffid"     "P = 0.673"
 [2,] "motherht"    "P = 0.000"
 [3,] "sex"         "P = 0.000"
 [4,] "month"       "P = 0.061"
 [5,] "aged"        "P = 0.013"
 [6,] "Ncomp"       "P = 0.071"
 [7,] "cow"         "P = 0.007"
 [8,] "goat"        "P = 0.296"
 [9,] "chicken"     "P = 0.002"
[10,] "dog"         "P = 0.206"
[11,] "mother_age"  "P = 0.000"
[12,] "mother_edu"  "P = 0.000"
[13,] "water_time"  "P = 0.462"
[14,] "roof"        "P = 0.023"
[15,] "floor"       "P = 0.021"
[16,] "elec"        "P = 0.019"
[17,] "radio"       "P = 0.128"
[18,] "tv"          "P = 0.000"
[19,] "mobilephone" "P = 0.003"
[20,] "clock"       "P = 0.024"
[21,] "bicycle"     "P = 0.817"
[22,] "motorcycle"  "P = 0.264"
[23,] "stove"       "P = 0.000"
[24,] "u18"         "P = 0.064"
[25,] "HHS"         "P = 0.060"


Covariates selected (P<0.20):
      [,1]          [,2]       
 [1,] "motherht"    "P = 0.000"
 [2,] "sex"         "P = 0.000"
 [3,] "month"       "P = 0.061"
 [4,] "aged"        "P = 0.013"
 [5,] "Ncomp"       "P = 0.071"
 [6,] "cow"         "P = 0.007"
 [7,] "chicken"     "P = 0.002"
 [8,] "mother_age"  "P = 0.000"
 [9,] "mother_edu"  "P = 0.000"
[10,] "roof"        "P = 0.023"
[11,] "floor"       "P = 0.021"
[12,] "elec"        "P = 0.019"
[13,] "radio"       "P = 0.128"
[14,] "tv"          "P = 0.000"
[15,] "mobilephone" "P = 0.003"
[16,] "clock"       "P = 0.024"
[17,] "stove"       "P = 0.000"
[18,] "u18"         "P = 0.064"
[19,] "HHS"         "P = 0.060"
> 
> # subset data frame to Ws selected in prescreening
> ed=e[,c("block","hhid","childid","clusterid","haz",Ws.haz)]
> 
> # subset to complete cases
> ed=ed[complete.cases(ed),]
> 
> # diarrhea
> Wcols.diarr=colnames(d)[-which(colnames(d)%in%c("block","hhid","childid","clusterid","tr","diarr7"))]
> Ws.diarr=Wprescreen(Y=d$diarr7, Ws=d[,Wcols.diarr],family="gaussian")

Likelihood Ratio Test P-values:
      [,1]          [,2]       
 [1,] "staffid"     "P = 0.000"
 [2,] "motherht"    "P = 0.082"
 [3,] "sex"         "P = 0.773"
 [4,] "month"       "P = 0.947"
 [5,] "aged"        "P = 0.006"
 [6,] "Ncomp"       "P = 0.445"
 [7,] "cow"         "P = 0.253"
 [8,] "goat"        "P = 0.576"
 [9,] "chicken"     "P = 0.482"
[10,] "dog"         "P = 0.156"
[11,] "mother_age"  "P = 0.039"
[12,] "mother_edu"  "P = 0.589"
[13,] "water_time"  "P = 0.667"
[14,] "roof"        "P = 0.488"
[15,] "floor"       "P = 0.118"
[16,] "elec"        "P = 0.746"
[17,] "radio"       "P = 0.837"
[18,] "tv"          "P = 0.772"
[19,] "mobilephone" "P = 0.324"
[20,] "clock"       "P = 0.564"
[21,] "bicycle"     "P = 0.509"
[22,] "motorcycle"  "P = 0.718"
[23,] "stove"       "P = 0.410"
[24,] "u18"         "P = 0.149"
[25,] "HHS"         "P = 0.915"


Covariates selected (P<0.20):
     [,1]         [,2]       
[1,] "staffid"    "P = 0.000"
[2,] "motherht"   "P = 0.082"
[3,] "aged"       "P = 0.006"
[4,] "dog"        "P = 0.156"
[5,] "mother_age" "P = 0.039"
[6,] "floor"      "P = 0.118"
[7,] "u18"        "P = 0.149"
> 
> # subset data frame to Ws selected in prescreening
> dd=d[,c("block","hhid","childid","clusterid","diarr7",Ws.diarr)]
> 
> # subset to complete cases
> dd=dd[complete.cases(dd),]
> 
> # sort
> dd=dd[order(dd$block, dd$clusterid, dd$hhid, dd$childid),]
> 
> 
> 
> # --------------------------------------
> # fit model
> # --------------------------------------
> # define SuperLearner libraries
> SL.library<-list("SL.mean","SL.glm","SL.bayesglm","SL.gam","SL.glmnet")
> # for adjusted permutation test, fit model of outcome
> # as a function of covariates excluding treatment assignment
> 
> sl.haz=sl.prep(ed,y="haz")

Number of obs in analysis data frame
[1] 1414
> colnames(sl.haz$A)
 [1] "motherht"                   "aged"                      
 [3] "Ncomp"                      "cow"                       
 [5] "chicken"                    "motherage"                 
 [7] "u18"                        "sexMale"                   
 [9] "month2"                     "month3"                    
[11] "month4"                     "month5"                    
[13] "month6"                     "month7"                    
[15] "month8"                     "month9"                    
[17] "month10"                    "month11"                   
[19] "month12"                    "mothereduAnysecondary"     
[21] "mothereduCompleteprimary"   "roofIronother"             
[23] "floorCementconcrete"        "elecHaselectricity"        
[25] "radioHasradio"              "tvOwnsTV"                  
[27] "mobilephoneAnymobilephones" "clockHasclock"             
[29] "stoveHasstove"              "HHSMissing"                
[31] "HHSModerate"                "HHSSevere"                 
> 
> sl.diarr=sl.prep(dd,y="diarr7") 

Number of obs in analysis data frame
[1] 2759
> colnames(sl.diarr$A)
 [1] "motherht"      "aged"          "dog"           "motherage"    
 [5] "u18"           "staffid3438"   "staffid3448"   "staffid3450"  
 [9] "staffid3458"   "staffid3500"   "staffid4188"   "staffid4302"  
[13] "staffid4310"   "staffid4312"   "staffid4317"   "staffid4405"  
[17] "staffid4417"   "staffid4430"   "staffid4437"   "staffid4525"  
[21] "staffid4534"   "staffid4538"   "staffid4602"   "staffid4630"  
[25] "staffid4648"   "staffid4785"   "staffid4838"   "staffid5348"  
[29] "staffid5423"   "staffid5424"   "staffid5618"   "staffid7838"  
[33] "staffid7840"   "staffid8247"   "staffid8601"   "staffid8603"  
[37] "staffid8882"   "floorConcrete"
> 
> set.seed(67890)
> sl.haz.fit=SuperLearner(Y=sl.haz$Y, X=sl.haz$A, SL.library=SL.library,
+     id=sl.haz$clusterid,family="gaussian",method="method.NNLS")
Loading required package: arm
Loading required package: MASS
Loading required package: Matrix
Loading required package: lme4

arm (Version 1.8-6, built: 2015-7-7)

Working directory is /Users/jadederong/Documents/CRG/wash-benefits/kenya/src/primary/analysis/10-btw-clus-spill

Loading required package: gam
Loading required package: splines
Loading required package: foreach
Loaded gam 1.12

Loading required package: glmnet
Loaded glmnet 2.0-2

> sl.haz.fit

Call:  
SuperLearner(Y = sl.haz$Y, X = sl.haz$A, family = "gaussian", SL.library = SL.library,  
    method = "method.NNLS", id = sl.haz$clusterid) 


                    Risk      Coef
SL.mean_All     1.193942 0.2171517
SL.glm_All      1.107443 0.0000000
SL.bayesglm_All 1.107181 0.0000000
SL.gam_All      1.084040 0.7828483
SL.glmnet_All   1.093130 0.0000000
> 
> set.seed(67890)
> sl.diarr.fit=SuperLearner(Y=sl.diarr$Y, X=sl.diarr$A, SL.library=SL.library,
+      id=sl.diarr$clusterid,family="binomial",method="method.NNLS")
Warning messages:
1: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
2: In predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type ==  :
  prediction from a rank-deficient fit may be misleading
> sl.diarr.fit

Call:  
SuperLearner(Y = sl.diarr$Y, X = sl.diarr$A, family = "binomial", SL.library = SL.library,  
    method = "method.NNLS", id = sl.diarr$clusterid) 


                     Risk      Coef
SL.mean_All     0.1986767 0.1860318
SL.glm_All      0.1906362 0.0000000
SL.bayesglm_All 0.1904985 0.0000000
SL.gam_All      0.1899872 0.8139682
SL.glmnet_All   0.1906697 0.0000000
> 
> # generate residuals
> resid.haz=sl.haz$Y - sl.haz.fit$SL.predict
> resid.diarr=sl.diarr$Y - sl.diarr.fit$SL.predict
> 
> resid.df.haz=data.frame(hhid=ed$hhid,haz=resid.haz)
> resid.df.diarr=data.frame(hhid=dd$hhid,diarr7=resid.diarr)
> 
> #----------------------------------------------------
> # Count the number of treated compounds within a control
> # compound for a given set of treatments
> #----------------------------------------------------
> W.comp2km=comp2km(anyW.mat)
> S.comp2km=comp2km(anyS.mat)
> H.comp2km=comp2km(anyH.mat)
> N.comp2km=comp2km(anyN.mat)
> 
> # get the number of compounds within 2 km  - any tr
> C.comp2km=comp2km(C.mat)
> 
> W.comp2km$prop=W.comp2km$comp2km / C.comp2km$comp2km
> S.comp2km$prop=S.comp2km$comp2km / C.comp2km$comp2km
> H.comp2km$prop=H.comp2km$comp2km / C.comp2km$comp2km
> N.comp2km$prop=N.comp2km$comp2km / C.comp2km$comp2km
> 
> #----------------------------------------------------
> # Run permutation test - HAZ - unadjusted
> #----------------------------------------------------
> B=100000
> 
> set.seed(67890)
> W.perm.haz=myperm.test(W.comp2km,y="haz",ydata=resid.df.haz,B)
> set.seed(67890)
> S.perm.haz=myperm.test(S.comp2km,y="haz",ydata=resid.df.haz,B)
> set.seed(67890)
> H.perm.haz=myperm.test(H.comp2km,y="haz",ydata=resid.df.haz,B)
> set.seed(67890)
> N.perm.haz=myperm.test(N.comp2km,y="haz",ydata=resid.df.haz,B)
> 
> # combine results
> out.list=list(W.perm.haz,S.perm.haz,H.perm.haz,N.perm.haz)
> perm.haz.dist.adj_j=t(sapply(out.list,format.perm))
> 
> 
> #----------------------------------------------------
> # Run permutation test - HAZ - unadjusted
> #----------------------------------------------------
> B=100000
> 
> set.seed(67890)
> W.perm.diar=myperm.test(W.comp2km,y="diarr7",ydata=resid.df.diarr,B)
> set.seed(67890)
> S.perm.diar=myperm.test(S.comp2km,y="diarr7",ydata=resid.df.diarr,B)
> set.seed(67890)
> H.perm.diar=myperm.test(H.comp2km,y="diarr7",ydata=resid.df.diarr,B)
> set.seed(67890)
> N.perm.diar=myperm.test(N.comp2km,y="diarr7",ydata=resid.df.diarr,B)
> 
> # combine results
> out.list=list(W.perm.diar,S.perm.diar,H.perm.diar,
+               N.perm.diar)
> perm.diarr.dist.adj_j=t(sapply(out.list,format.perm))
> 
> 
> 
> coln=colnames(perm.haz.dist.adj_j)
> newlaz=matrix(NA,4,6)
> newdiar=matrix(NA,4,6)
> for(i in 1:ncol(perm.haz.dist.adj_j)){
+   newlaz[,i]=unlist(perm.haz.dist.adj_j[,i])
+   newdiar[,i]=unlist(perm.diarr.dist.adj_j[,i])
+ }
> perm.haz.dist.adj_j=as.data.frame(newlaz)
> perm.diarr.dist.adj_j=as.data.frame(newdiar)
> colnames(perm.haz.dist.adj_j)=coln
> colnames(perm.diarr.dist.adj_j)=coln
> 
> rownames(perm.haz.dist.adj_j)=c("Water","Sanitation","Handwashing","Nutrition")
> rownames(perm.diarr.dist.adj_j)=c("Water","Sanitation","Handwashing","Nutrition")
> 
> save(perm.haz.dist.adj_j, perm.diarr.dist.adj_j,
+      file="~/Dropbox/WBK-primary-analysis/results/jade/spill-dist-adj.RData")
> 
> 
> proc.time()
    user   system  elapsed 
6511.382  361.891 6897.264 
